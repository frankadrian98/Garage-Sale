from _lexer.token_ import TokenRegex


token_matcher = [
        TokenRegex('type', '(([A-Z][a-zA-Z]*)|(list|(void|(bool|(float|(int|string))))))'),
        TokenRegex('true','true'),
        TokenRegex('false','false'),
        TokenRegex('null','null'),       
        TokenRegex('pl','\('),
        TokenRegex('pr','\)'),
        TokenRegex('bl','\{'),
        TokenRegex('br','\}'),
        TokenRegex('sbl','\['),
        TokenRegex('sbr','\]'),
        TokenRegex('float','([1-9][0-9]*(\.[0-9]*)|0\.[0-9]*)'),
        TokenRegex('int','([1-9][0-9]*|0)'),
        TokenRegex('string','"([^"\n]|(\\"))*"'),
        TokenRegex('comma',','),
        TokenRegex('space',' +',lambda a: None),
        TokenRegex('newline','\n',lambda a: None),
        TokenRegex('add','\+'),
        TokenRegex('scolon',';'),
        TokenRegex('minus','\-'),      
        TokenRegex('mult','\*'),
        TokenRegex('div','\/'),
        TokenRegex('if','if'),
        TokenRegex('else','else'),
        TokenRegex('while','while'),
        TokenRegex('continue','continue'),
        TokenRegex('break','break'),
        TokenRegex('return','return'),
        TokenRegex('and','and'),
        TokenRegex('or','or'),
        TokenRegex('greatequal','>='),
        TokenRegex('lessequal','<='),
        TokenRegex('great','>'),
        TokenRegex('less','<'),
        TokenRegex('equal','=='),
        TokenRegex('assign',':='),       
        TokenRegex('notequal','!='),
        TokenRegex('dot','\.'),
        TokenRegex('not','not'),
        TokenRegex('word','[a-z][a-zA-Z0-9_]*'),
        ]